#!/usr/bin/env python3
"""
SAAC Compression with CLIP Scene Classification

Example script demonstrating CLIP-based scene understanding for
superior compression intent detection.
"""

import sys
import os
from saac import SaacCompressor


def main():
    if len(sys.argv) < 2:
        print("Usage: python3 compress_with_clip.py <input_image>")
        print("\nüéØ SAAC with CLIP Scene Classification")
        print("="*70)
        print("Advanced compression with semantic scene understanding")
        print("")
        print("CLIP Benefits:")
        print("  ‚úì 54 intent categories for comprehensive coverage")
        print("  ‚úì 85-95% scene classification accuracy")
        print("  ‚úì Semantic understanding of image context")
        print("  ‚úì Probability distributions for complex scenes")
        print("  ‚úì Zero-shot learning (no training needed)")
        print("")
        print("Coverage:")
        print("  From portraits to landscapes, food to pets, sports to documents,")
        print("  weddings to garbage pics - everything is covered!")
        print("")
        print("Requirements:")
        print("  ‚Ä¢ pip install git+https://github.com/openai/CLIP.git")
        print("")
        print("="*70)
        sys.exit(1)
    
    input_path = sys.argv[1]
    
    if not os.path.exists(input_path):
        print(f"Error: File not found: {input_path}")
        sys.exit(1)
    
    base_name = os.path.splitext(os.path.basename(input_path))[0]
    output_path = f"{base_name}_compressed.png"  # PNG output with pixel-level compression
    
    print(f"Compressing: {input_path}")
    print("="*70)
    
    # Detect device
    try:
        import torch
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        if device == 'cuda':
            print("‚úì GPU detected - using CUDA acceleration")
        else:
            print("‚ÑπÔ∏è  Using CPU")
    except:
        device = 'cpu'
        print("‚ÑπÔ∏è  Using CPU")
    
    print()
    
    # Check CLIP availability
    try:
        import clip
        print("‚úì CLIP installed")
    except ImportError:
        print("‚ùå CLIP not installed!")
        print("Install with: pip install git+https://github.com/openai/CLIP.git")
        sys.exit(1)
    
    print()
    
    # Create compressor with CLIP scene classification
    print("Initializing SAAC with CLIP scene classifier...")
    print("-"*70)
    
    compressor = SaacCompressor(
        device=device,
        yolo_model='yolov8n-seg.pt',
        saliency_method='spectral',
        segmentation_method='simple',
        scene_method='clip',  # ‚Üê Use CLIP for scene classification
        enable_saliency=True,
        enable_segmentation=True,
        blend_mode='priority',
        compression_mode='pixel'  # Pixel-level compression for PNG output
    )
    
    # Compress
    stats = compressor.compress_image(
        input_path=input_path,
        output_path=output_path,
        save_visualizations=True,
        visualization_dir='visualizations'
    )
    
    # Print summary
    print("\n" + "="*70)
    print("COMPRESSION SUMMARY (CLIP-Enhanced)")
    print("="*70)
    print(f"Input:          {input_path}")
    print(f"Output:         {output_path}")
    print(f"\nüéØ CLIP Scene Analysis:")
    print(f"  Primary Scene:  {stats['scene']}")
    print(f"  Confidence:     {stats['scene_confidence']:.1%}")
    print(f"  Description:    {compressor.scene_classifier.get_scene_description(stats['scene'])}")
    
    # If CLIP classifier is available, show probability distribution
    if hasattr(compressor.scene_classifier, 'classify_with_probabilities'):
        print(f"\nüìä Scene Probability Distribution:")
        import cv2
        image = cv2.imread(input_path)
        probs_dict = compressor.scene_classifier.get_scene_probabilities_dict(image)
        
        # Show top 4 scenes
        sorted_probs = sorted(probs_dict.items(), key=lambda x: x[1], reverse=True)[:4]
        for scene, prob in sorted_probs:
            bar_length = int(prob * 30)
            bar = "‚ñà" * bar_length
            print(f"  {scene:12s} {bar} {prob:5.1%}")
    
    print(f"\nüì¶ Compression Results:")
    print(f"  Objects found:  {stats['detections']}")
    print(f"  Original size:  {stats['original_size_mb']:.2f} MB")
    
    if stats.get('hevc_size_mb'):
        print(f"  PNG output:     {stats['compressed_size_mb']:.2f} MB ({stats['compression_ratio']:.2f}x)")
        print(f"  HEVC backup:    {stats['hevc_size_mb']:.2f} MB ({stats['hevc_compression_ratio']:.2f}x)")
        print(f"  PNG savings:    {stats['space_saved_percent']:.1f}% (compressed pixels)")
    else:
        print(f"  Compressed:     {stats['compressed_size_mb']:.2f} MB")
        print(f"  Ratio:          {stats['compression_ratio']:.2f}x")
        print(f"  Space saved:    {stats['space_saved_percent']:.1f}%")
    
    print(f"  Processing:     {stats['processing_time_seconds']:.1f}s")
    
    print(f"\nüìà Quality Allocation:")
    qp_stats = stats['qp_statistics']
    print(f"  High quality:   {qp_stats['high_quality_percent']:.1f}% (faces, objects)")
    print(f"  Medium quality: {qp_stats['medium_quality_percent']:.1f}% (moderate importance)")
    print(f"  Low quality:    {qp_stats['low_quality_percent']:.1f}% (backgrounds)")
    
    print(f"\nüìÅ Visualizations: visualizations/")
    print("="*70)
    
    print("\n‚ú® Check visualizations/ folder for quality maps:")
    print("   ‚Ä¢ _detections.jpg - Segmentation masks")
    print("   ‚Ä¢ _prominence.jpg - Prominence scores")
    print("   ‚Ä¢ _qp_map.jpg - Quality allocation map")
    print("   ‚Ä¢ _saliency.jpg - Saliency heatmap")
    print("   ‚Ä¢ _scene.jpg - Detected scene type")
    
    print("\nüí° CLIP Advantage:")
    print("   Semantic scene understanding with 54 intent categories ensures")
    print("   optimal quality allocation based on image context.")
    print("\nüìö Supported Intent Categories:")
    print("   ‚Ä¢ People: portrait, selfie, group_photo, baby, children")
    print("   ‚Ä¢ Animals: pet_portrait, wildlife, garden, park")
    print("   ‚Ä¢ Food: restaurant, food_closeup, cooking")
    print("   ‚Ä¢ Outdoor: landscape, beach, mountain, snow")
    print("   ‚Ä¢ Urban: urban, street, architecture")
    print("   ‚Ä¢ Sports: sports, gym, concert")
    print("   ‚Ä¢ Events: wedding, party")
    print("   ‚Ä¢ Indoor: indoor, living_room, bedroom, bathroom, kitchen")
    print("   ‚Ä¢ Work: workspace, meeting, classroom")
    print("   ‚Ä¢ Commercial: retail, product, vehicle, transportation, travel")
    print("   ‚Ä¢ Technical: document, screenshot, barcode_qr")
    print("   ‚Ä¢ Special: night, medical, studio, abstract, macro")
    print("   ‚Ä¢ Low quality: low_quality, blurry, meme, collage")
    print("   ‚Ä¢ Aerial/underwater, fashion, museum, and more!")
    print("\n   ‚Üí One way or another, your image is covered!")


if __name__ == '__main__':
    main()
